---
layout: post
title: "记录aicamp遇到的问题(按时间长期更新)"
date:   2024-8-3
tags: [aicamp]
comments: false
author: directorhorse
---
## 2024/8/3
### cuda与文件后缀
根据我的测试，cuda的编译器nvcc是通过后缀名来识别c和cuda文件的。如果一个文件里用了cuda函数但后缀名不是cu而是c，就会编译出错。
## 2024/8/10
### 记录一个cuda遇到的bug
在实现softmax的时候遇到了一个奇怪的问题，测试样例有[32,1024,2048]*一共9种。每次单独测试都成功，但一个for循环里测试9个就会导致多次重复运行结果不同。代码如下所示
```
__global__ void softmax(float *input, float *output, int M, int N)
{
    int row = blockIdx.x;
    __shared__ float tmp[BLOCK_DIM];
    __shared__ float globalMax;
    __shared__ float globalSum;
    //-----------
    float val = -__FLT_MAX__;
    for (int i = threadIdx.x; i < N; i += BLOCK_DIM)//
    {
        val = max(val, input[row * N + i]);
    }
    tmp[threadIdx.x] = val;
    __syncthreads();
    for (int step = BLOCK_DIM / 2; step > 0; step /= 2)
    {
        if (threadIdx.x < step)
        {
            tmp[threadIdx.x] = max(tmp[threadIdx.x], tmp[threadIdx.x + step]);
        }
        __syncthreads();
    }
    if (threadIdx.x == 0)
    {
        globalMax = tmp[0];
    }
    __syncthreads();
    //-----------

    val = 0.0f;
    for (int i = threadIdx.x; i < N; i += BLOCK_DIM)
    {
        val += __expf(input[row * N + i] - globalMax);
    }
    tmp[threadIdx.x] = val;
    __syncthreads();
    for (int step = BLOCK_DIM / 2; step > 0; step /= 2)
    {
        if (threadIdx.x < step)
        {
            tmp[threadIdx.x] += tmp[threadIdx.x + step];
        }
        __syncthreads();
    }
    if (threadIdx.x == 0)
    {
        globalSum = tmp[0];
    }
    __syncthreads();
    for (int i = threadIdx.x; i < N; i += BLOCK_DIM)
    {
        output[row * N + i] = __expf(input[row * N + i] - globalMax) * __fdividef(1.0F, globalSum);
    }
    __syncthreads();
}
```
后来发现解决方案为在每次赋值后加上_syncthreads()，同步几个线程